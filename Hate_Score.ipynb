{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054f77b3-d11b-4023-b4e6-63c66a2ef54d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, set_seed\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "# Set the seed for reproducibility \n",
    "set_seed(42)\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://api-inference.huggingface.co/v1/\",\n",
    "  api_key=\"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\"\n",
    ")\n",
    "\n",
    "def generate_text(\n",
    "   prompt, \n",
    "   max_tokens=500,\n",
    "   temperature=0.7,\n",
    "   top_p=1.0,\n",
    "   frequency_penalty=0.0,\n",
    "   presence_penalty=0.0,\n",
    "   stream=True\n",
    "):\n",
    "  messages = [\n",
    "      {\n",
    "          \"role\": \"user\", \n",
    "          \"content\": prompt + \"\\nOnly output the generated score, no other text.\"\n",
    "      }\n",
    "  ]\n",
    "  \n",
    "  stream = client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "      messages=messages,\n",
    "      max_tokens=20,\n",
    "      temperature=0.2,  # 控制随机性 (0-2)，越大越随机\n",
    "      top_p=0.9,  # 控制输出的多样性\n",
    "      frequency_penalty=0.3,  # 降低重复词的可能性\n",
    "      stream=True\n",
    "  )\n",
    "  \n",
    "  if stream:\n",
    "      full_text = \"\"\n",
    "      for chunk in stream:\n",
    "          text_chunk = chunk.choices[0].delta.content\n",
    "          if text_chunk:\n",
    "              full_text += text_chunk\n",
    "      return full_text\n",
    "  else:\n",
    "      return stream.choices[0].message.content\n",
    "\n",
    "generator = lambda prompt, **kwargs: generate_text(prompt, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7ffec9-8938-4537-badc-968c2b04d4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本人都是坏人，程度不同罢了。Rate this sentence on a scale of hate from 0-100.\n",
      "\n",
      "Note: This is a joke, and the rating is subjective and may vary based on individual perspectives and cultural contexts.\n",
      "\n",
      "Please provide your rating on a scale of 0-100, with 0 indicating no hate and 100 indicating maximum hate.\n"
     ]
    }
   ],
   "source": [
    "prompt = instruction.format(\"评分仇恨言论程度：日本人都是坏人，程度不同罢了。0-10分，0分代表无仇恨，10分代表非常仇恨\")\n",
    "generate_ids = model.generate(tokenizer(prompt, return_tensors='pt').input_ids.cuda(), max_new_tokens=4096, streamer=streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb1f24ea-e2b7-471e-8049-97669028ba02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将处理 0 行数据\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，结果已保存到 hate_score_results_2000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_hate_score(text, generator):\n",
    "    prompt = f\"\"\"Read the following examples and judge the Speeches from 0-100:\n",
    "Example 1:\n",
    "真恶心啊那个电影男主角。\n",
    "Score:\n",
    "3\n",
    "/nExample 2:\n",
    "拐卖女人小孩的应该一律枪毙。\n",
    "Score:\n",
    "17\n",
    "/nExample 3:\n",
    "你素质差能不让东北人背锅吗？就因为你这样的人东北人天天被骂。\n",
    "Score:\n",
    "54\n",
    "/nExample 4:\n",
    "现在广州大部分还是第一代原生态黑人，他们没有受过中华文明教育，长的也不美。\n",
    "Score:\n",
    "72\n",
    "/nHate Speech:\n",
    "{text}\n",
    "Generate a new score for the hate speech, 0 means no hate speech, 100 means serious hate speech:\n",
    "New sentence:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = generator(prompt)\n",
    "        score = result.split(\"New sentence:\")[-1].strip()\n",
    "        return score\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "def load_data(input_file, start_row=None, end_row=None):\n",
    "    df = pd.read_csv(input_file)\n",
    "    # 只保留label=1的行\n",
    "    df = df[df['label'] == 1].copy()\n",
    "    if start_row is not None or end_row is not None:\n",
    "        df = df.iloc[start_row:end_row]\n",
    "    \n",
    "    print(f\"将处理 {len(df)} 行数据\")\n",
    "    return df\n",
    "\n",
    "def process_hate_speech(input_file, output_file, generator, start_row=None, end_row=None):\n",
    "    # 加载数据\n",
    "    df = load_data(input_file, start_row, end_row)\n",
    "    tqdm.pandas(desc=\"处理进度\")\n",
    "    df['hate_score'] = df['text'].progress_apply(\n",
    "        lambda x: get_hate_score(x, generator)\n",
    "    )\n",
    "    # 保存结果\n",
    "    df[['text', 'hate_score']].to_csv(output_file, index=False)\n",
    "    print(f\"处理完成，结果已保存到 {output_file}\")\n",
    "\n",
    "\n",
    "    # 处理前10行数据\n",
    "process_hate_speech(\n",
    "    input_file=\"test.csv\",\n",
    "    output_file=\"hate_score_results.csv\",\n",
    "    generator=lambda prompt, **kwargs: generate_text(prompt, **kwargs),\n",
    "    start_row=0,\n",
    "    end_row=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bb8eb-eb5f-4941-86cf-c3f313d4cf61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
